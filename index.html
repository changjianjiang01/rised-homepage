<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PanopticRecon++: Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction">
  <meta name="keywords" content="Autonomous Driving, NeRF, multiple cameras">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PanopticRecon++: Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction</title> 
  <!-- <br>ICML2024 -->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">
  <link rel="stylesheet" type="text/css" href="./static/css/test.css">
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css"> -->
  <link rel="stylesheet" href="./static/css/app.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <style>
    .video-container1 {
      display: flex;
      flex-wrap: wrap;
      justify-content: flex-start;
    }

    .video1 {
      flex: 1 0 22%;
      margin: 8px;
    }
    .divider {
    position: absolute;
    left: 50%;
    top: 0;
    bottom: 0;
    width: 2px;
    background-color: rgb(195, 192, 192);
  }
  .indented {
  margin-top: 2em;
  }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://yuxuan1206.github.io/NFAtlas/">
            NF-Atlas
          </a>
          <a class="navbar-item" href="https://yuxuan1206.github.io/PanopticRecon/">
            PanopticRecon
          </a>
          <a class="navbar-item" href="https://github.com/YunxuanMao/ngel_slam">
            NGEL-SLAM
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<div class="columns is-centered has-text-centered">
  <!-- <div class="column is-four-fifths"> -->
    <div class="content has-text-justified">
      <img src="./static/images/logo.png"
      width="150">
    </div>
  <!-- </div> -->
</div>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction</h1>
          <!-- <h1 class="is-size-4 publication-authors">IROS 2024 (Oral)</h1> -->
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block"> 
             Xuan Yu</a>,</span>
              <span class="author-block">
                Yuxuan Xie</a>,</span>
              <span class="author-block"> 
                 Yili Liu</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?user=RiX5SJUAAAAJ&hl=zh-CN" target="_blank">Sitong Mao</a>,</span>
                      <span class="author-block">
                        <a href="https://scholar.google.com/citations?user=d5qY3q0AAAAJ&hl=en" target="_blank">Shunbo Zhou</a>,</span>
                        <span class="author-block">
                          <a href="https://scholar.google.com.hk/citations?user=dNAbVgIAAAAJ&hl=zh-CN" target="_blank">Haojian Lu</a>,</span>
                          <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=1hI9bqUAAAAJ&hl=en" target="_blank">Rong Xiong</a>,</span>
                                <span class="author-block">
                                  <a href="https://yiyiliao.github.io/" target="_blank">Yiyi Liao</a>,</span>
                                      <span class="author-block">
                                        <a href="https://ywang-zju.github.io/" target="_blank">Yue Wang</a><sup>*</sup>
                                      </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Zhejiang University,</span>
            <span class="author-block"><sup>2</sup>Huawei,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.14650-"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yuxuan1206/PanopticRecon_pp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(coming soon)</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser"> -->

<!-- </section> -->

   <!-- <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
    </div>
  </div>  -->

   <!-- Paper video. -->

   <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <!-- <h2 class="title is-3">Method</h2>  -->
      <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
         <source src="./static/videos/teaser.mp4"
                 type="video/mp4">
        </video>
  <!--/ Paper video. -->

  <!-- <div class="image-container">
    <div class="image-overlay"></div>
    <img src="./static/images/zipdemo1.png" alt="Image 1" class="image image1">
    <img src="./static/images/ucdemo1.png" alt="Image 2" class="image image2">
  </div> -->
<!-- </section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- <div id="outer-container">
  <div id="container">
    <img id="image1" src="./static/images/ucdemo1.png" />
    <div id="slider">
      <div class="arrow-right">&#9654;</div>
      <div class="arrow-left">&#9664;</div>
    </div>
    <img id="image2" src="./static/images/zipdemo1.png" />
  </div>
</div>
<script src="./static/js/test.js"></script> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents an end-to-end open-vocabulary panoptic reconstruction method using a 2D vision-language model (VLM). We identify three key challenges: 1) 2D instance IDs misalignment across frames, 2) ambiguity in instance association for objects that never co-occur in an image, and 3) inconsistency between semantic and instance segmentation  from independent networks.
            <strong>We propose PanopticRecon++, an end-to-end open-vocabulary panoptic reconstruction method based on cross-attention. Our key idea is to model instances using explicit queries, enabling the construction of spatially aware queries and keys for attention map computation, thereby incorporating 3D spatial priors without post-processing and facilitating consistent instance-level semantic.</strong> 
            Specifically, we propose learnable Gaussian-modulated instance tokens as queries, aligned with 2D instance IDs across frames by linear assignment. Incorporating segmentation features and spatial prior into the attention map, we avoid the redundant instance IDs caused by limited field of view. A parameter-free panoptic head ensures semantic-instance segmentation consistency. Furthermore, token numbers are dynamically adjusted during training to match the number of objects. 
          </p>
          <!-- <p>
          We evaluate PanopticRecon++'s 3D and 2D segmentation and reconstruction performance on simulated and real-world datasets. Experiments demonstrate that PanopticRecon++ outperforms other open-vocabulary methods, particularly in scenes with numerous objects of varying sizes.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <br>

    <!-- Motivation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
        
          <img src="./static/images/motivation.png">
          <p>
            End-to-end open-vocabulary panoptic reconstruction by 2D foundation model faces three challenges:  
            <p>
              <strong>1) Misalignment:</strong> 2D instance IDs across frames are not align. 
              <br>
              <strong>2) Ambiguity:</strong> Due to the limited FoV, two objects that never co-occur in an image can be the same or different instances. 
              <br>
              <strong>3) Inconsistency:</strong> The semantic and instance segmentations obtained from two independent networks are inconsistent. 
            </p>
            We align 2D instance IDs by instance tokens linear assignment, eliminate the ambiguity of 3D instances by incorporating spatial prior, and output consistent semantic and instance masks by a parameter-free panoptic head, generating the geometric mesh with panoptic masking that allows for multi-branch novel-view synthesis.
          </p>
        </div>
      </div>
    </div>

    <!-- Paper video. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/method.mp4"
                   type="video/mp4">
          </video>
    <!--/ Paper video. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/comparison_outdoor.mp4"
                   type="video/mp4">
          </video>
      </div>
          <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
             <source src="./static/videos/comparison_indoor.mp4"
                     type="video/mp4">
            </video>
        </div>
    <!--/ Paper video. -->

    <body>
      <video id="video1" width="640" height="360" controls>
          <source src="./static/videos/method.mp4" type="video/mp4">
          Your browser does not support the video tag.
      </video>
      <video id="video2" width="640" height="360" controls style="display:none;">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
          Your browser does not support the video tag.
      </video>
      <canvas id="video1Merge" width="640" height="360"></canvas>
  
      <script src="./static/js/video_comparison.js"></script>
      <script>
          document.addEventListener('DOMContentLoaded', function() {
              var video1 = document.getElementById('video1');
              var video2 = document.getElementById('video2');
              resizeAndPlay(video1);
          });
      </script>
  </body>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">More Results</h3>
    </div>

   <!--/ Re-rendering. -->

   <p>
    <strong style="color: blue";> 
    Note that no prior used in our GaussianPro.
    </strong>
  </p>
   <section class="hero is-light is-small">
     <div class="hero-body">
       <div class="container">
           <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/scene100613.mp4"
                    type="video/mp4">
           </video>
       </div>
       <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/scene148697.mp4"
                  type="video/mp4">
        </video>
    </div>
    <div class="container">
      <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/scene164701.mp4"
                type="video/mp4">
      </video>
      <br>
      <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Images</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Depth</b> &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Normal</b></p>
      <br>
  </div>
     </div>
   </section>
   <br>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">Mesh Visualization</h3>
    </div>

   <p>
    <strong style="color: black";> 
      Please note that we did not perform any additional processing on the sky, 
      but it is possible to separate the sky from the foreground by segmenting them as an independent layer during modeling.
    </strong>
  </p>
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_baseline.mp4" type="video/mp4">
           </video>
         </div>
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_baseline.mp4" type="video/mp4">
           </video>
         </div>

         <br>
         <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Ours GaussianPro (left)</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>3DGS (right)</b></p>
         <br>

      </div>
    </div>
  </section>
   <br>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <!--<pre><code>@misc{cheng2023ucnerf,
  title     = {UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras in autonomous driving},
  author    = {Kai Cheng and Xiaoxiao Long and Wei Yin and Jin Wang and Zhiqiang Wu and Yuexin Ma and Kaixuan Wang and Xiaozhi Chen and Xuejin Chen},
  year      = {2023},
  eprint={2311.16945},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}</code></pre>-->
    <pre><code>...
</code></pre>
    <!--<pre><code>@article{kchenguc23,
  author    = {Kai Cheng, Xiaoxiao Long, Wei Yin, Jin Wang, Zhiqiang Wu, Yuexin Ma, Kaixuan Wang, Xiaozhi Chen, Xuejin Chen},
  title     = {UC-NeRF},
  journal   = {arxiv},
  year      = {2023},
}</code></pre>-->
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
