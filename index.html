<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="RISED">
  <meta name="keywords" content="Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RISED</title> 

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">
  <link rel="stylesheet" type="text/css" href="./static/css/test.css">
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css"> -->
  <link rel="stylesheet" href="./static/css/app.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <link rel="stylesheet" href="./static/css/dics.min.css">
  <script src="./static/js/dics.min.js"></script>

  <style>
    .video-container1 {
      display: flex;
      flex-wrap: wrap;
      justify-content: flex-start;
    }

    .video1 {
      flex: 1 0 22%;
      margin: 8px;
    }
    .divider {
    position: absolute;
    left: 50%;
    top: 0;
    bottom: 0;
    width: 2px;
    background-color: rgb(195, 192, 192);
  }
  .indented {
  margin-top: 2em;
  }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/csy2.12116/">
            ER-Mapping
          </a>
          <a class="navbar-item" href="https://changjianjiang01.github.io/LI-GS/">
            LI-GS
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RISED: Accurate and Efficient RGB-Colorized Mapping Using Image Selection and Point Cloud Densification</h1>
          <h1 class="is-size-4 publication-authors">ICRA 2025</h1>

          <div class="columns is-centered has-text-centered">
          <!-- <div class="column is-four-fifths"> -->
<!--             <div class="content has-text-justified">
              <img src="./static/images/logo.png"
              width="120">
            </div> -->
          <!-- </div> -->
        </div>


          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
               <a href="https://scholar.google.com/citations?hl=en&user=V4miywEAAAAJ" target="_blank">Changjian Jiang</a>,</span>
                <span class="author-block">
                  Ruilan Gao</a>,</span>
                  <span class="author-block">
                    Kele Shao</a>,</span>
                      <span class="author-block">
                        <a href="https://ywang-zju.github.io/" target="_blank">Yue Wang</a>,</span>
                          <span class="author-block">
                            <a href="https://mypage.zju.edu.cn/rongxiong" target="_blank">Rong Xiong</a>,</span>
                              <span class="author-block">
                                  <span class="author-block">
                                    <a href="https://person.zju.edu.cn/zhangyu/" target="_blank">Yu Zhang</a><sup>*</sup></span>
                                      </div>

 

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://changjianjiang01.github.io/rised-homepage/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Arxiv(coming soon)</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=hekSMeu1ihg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://changjianjiang01.github.io/rised-homepage/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(coming soon)</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


   <!-- Paper video. -->

   <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <!-- <h2 class="title is-3">Method</h2>  -->
      <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
         <source src="./static/videos/teaser.mp4"
                 type="video/mp4">
        </video>
  <!--/ Paper video. -->



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent advances in robotics have underscored the critical role of colorized point clouds in enhancing environmental perception accuracy. However, conventional multi-sensor fusion Simultaneous Localization and Mapping (SLAM) systems typically employ all available camera images indiscriminately for point cloud colorization, resulting in suboptimal outcomes characterized by blurred textures. Notably, achieving precise texture-to-geometry alignment remains a persistent challenge despite the availability of accurate camera pose estimation. This study introduces RISED, an advanced colorized mapping system that tackles this challenge from two perspectives: projection accuracy and distribution uniformity. For projection accuracy, we analyze the influence of camera poses on colorization and carefully select the optimal viewpoint to minimize errors. Regarding distribution uniformity, point cloud densification is applied to eliminate LiDAR scanning traces. Furthermore, a novel evaluation method is introduced to provide comprehensive assessment of both accuracy and efficiency of colorized point clouds, filling a gap in this field. Experimental results show that our method outperforms traditional approaches in RGB-colorized mapping. Specifically, our method achieves notable improvements in projection accuracy (55.2%), geometric accuracy (63.1%), and surface coverage (30.8%).
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <br>

    <!-- Motivation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
        
          <img src="./static/images/motivation.png">
          <p>
            End-to-end open-vocabulary panoptic reconstruction by 2D foundation model faces three challenges:  
            <p>
              <strong>1) Misalignment:</strong> 2D instance IDs across frames are not align. 
              <br>
              <strong>2) Ambiguity:</strong> Due to the limited FoV, two objects that never co-occur in an image can be the same or different instances. 
              <br>
              <strong>3) Inconsistency:</strong> The semantic and instance segmentations obtained from two independent networks are inconsistent. 
            </p>
            We align 2D instance IDs by instance tokens linear assignment, eliminate the ambiguity of 3D instances by incorporating spatial prior, and output consistent semantic and instance masks by a parameter-free panoptic head, generating the geometric mesh with panoptic masking that allows for multi-branch novel-view synthesis.
          </p>
        </div>
      </div>
    </div>

    <!-- Paper video. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/method.mp4"
                   type="video/mp4">
          </video>
    <!--/ Paper video. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/comparison_outdoor.mp4"
                   type="video/mp4">
          </video>
      </div>
          <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
             <source src="./static/videos/comparison_indoor.mp4"
                     type="video/mp4">
            </video>
        </div> -->
    <!-- / Paper video. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparison</h2>

        <h3 class="title is-4">Panoptic / Semantic Mesh</h3>
        
        <!-- <div class="content has-text-centered"> -->
        <video class="video" width="45%" id="xyalias1" loop playsinline autoplay muted src="./static/videos/mesh-replica-pvlff-compress.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
        <canvas height=0 class="videoMerge" id="xyalias1Merge"></canvas>
        <!-- </div> -->
        <div class="content has-text-justified">
          <p>
            PVLFF has over segmentation and weak semantic segmentation accuracy, while our method can segment object-level instance and demonstrate high accuracy of panoptic/semantic segmentation and reconstruction quality.
          </p>
        </div>

        <!-- <div class="content has-text-centered"> -->
        <video class="video" width="45%" id="xyalias2" loop playsinline autoplay muted src="./static/videos/mesh-replica-PL-compress.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
        <canvas height=0 class="videoMerge" id="xyalias2Merge"></canvas>
        <!-- </div> -->
        <div class="content has-text-justified">
          <p>
            Panoptic Lifting relies only on 2D VLM mask observations without any 3D spatial prior, suffering from FoV limitation, resulting in some tables and chairs in different rooms have the same ID, while our method solves this problem by introducing 3D instance spatial prior.
          </p>
        </div>
        
        <h3 class="title is-4" style="margin-top: +20px">Panoptic / Semantic Rendering</h3>
        <div class="content has-text-justified">
          <p>
            ---
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias9" loop playsinline autoplay muted src="./static/videos/teaser2.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
          <canvas height=0 class="videoMerge" id="xyalias9Merge"></canvas>
        </div> 

        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Robotics Simulator</h2>
          <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/simulator.mp4"
                    type="video/mp4">
            </video>
          </div>
          <div class="content has-text-justified">
            <p>
            Jackal UGV starts navigation in Gazebo with the meshes generated from PanopticRecon++ trained on ScanNet++. 
            </p>
          </div>
        </div>
        

        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered" style="margin-top: +30px">More Results</h2>
        </div>

      </div>
    </div>

  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">More Results</h3>
    </div>

   <p>
    <strong style="color: blue";> 
    Note that no prior used in our GaussianPro.
    </strong>
  </p>
   <section class="hero is-light is-small">
     <div class="hero-body">
       <div class="container">
           <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/scene100613.mp4"
                    type="video/mp4">
           </video>
       </div>
       <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/scene148697.mp4"
                  type="video/mp4">
        </video>
    </div>
    <div class="container">
      <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/scene164701.mp4"
                type="video/mp4">
      </video>
      <br>
      <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Images</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Depth</b> &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Normal</b></p>
      <br>
  </div>
     </div>
   </section>
   <br>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">Mesh Visualization</h3>
    </div>

   <p>
    <strong style="color: black";> 
      Please note that we did not perform any additional processing on the sky, 
      but it is possible to separate the sky from the foreground by segmenting them as an independent layer during modeling.
    </strong>
  </p>
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_baseline.mp4" type="video/mp4">
           </video>
         </div>
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_baseline.mp4" type="video/mp4">
           </video>
         </div>

         <br>
         <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Ours GaussianPro (left)</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>3DGS (right)</b></p>
         <br>

      </div>
    </div>
  </section>
   <br>
</section> -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yu2025leveragecrossattentionendtoendopenvocabulary,
      title={Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction}, 
      author={Xuan Yu and Yuxuan Xie and Yili Liu and Haojian Lu and Rong Xiong and Yiyi Liao and Yue Wang},
      year={2025},
      eprint={2501.01119},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.01119}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
